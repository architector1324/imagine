## âœ¨ Imagine: A Lightweight Stable Diffusion Image Generation API

![](logo.png)

*Image generated by Imagine: "a photo of an astronaut riding a horse on mars, epic, cinematic, detailed"*

**Imagine** is a simple yet powerful HTTP server designed for generating images from text or other images using Stable Diffusion models and the Hugging Face `diffusers` library. It provides a single, straightforward endpoint that takes a JSON request and returns the generated image(s) as base64-encoded string(s), perfect for quick integration into your applications.

### Key Features

*   **Minimalist API:** One easy-to-use `/generate` endpoint for all your image generation needs.
*   **Versatile Generation:** Supports both **Text-to-Image (txt2img)** and **Image-to-Image (img2img)** capabilities.
*   **Live Progress Streaming:** Get real-time updates of the generation process by streaming intermediate steps directly to your client.
*   **Base64 Output:** Seamlessly receive generated images (both final and intermediate steps) as base64 strings, making them easy to embed directly into web pages, mobile apps, or other services without managing file storage.
*   **Comprehensive Parameters:** Control image generation parameters like `width`, `height`, `num_steps`, `guidance_scale`, `sampler`, `seed`, `negative_prompt`, **input image (`img`), diffusion strength (`strength`)**, and **floating-point precision (`fp_prec`)** via the JSON payload and server arguments.
*   **Offline Mode Support:** Run image generation completely offline once models are downloaded, ideal for local and secure deployments.
*   **Built with Flask & Diffusers:** Leveraging robust and popular Python libraries for reliability and ease of use.
*   **Hardware Agnostic:** Supports CPU, CUDA (NVIDIA), MPS (Apple Silicon), and potentially ROCm (AMD) depending on your PyTorch setup.

### Why Imagine?

**Imagine** is inspired by the philosophy of tools like **Ollama** and offers a similar approach for Stable Diffusion models. It is ideal for developers needing a lightweight solution to run Stable Diffusion image generation **as a local background service**.

This enables integration from **anywhere**: command-line scripts, Python applications, web pages, or other services. With **offline mode support**, you can ensure privacy and consistent performance. You no longer need to worry about the overhead and complexity of more feature-rich diffusion UIs; Imagine provides fast, API-driven access to Stable Diffusion, designed for seamless deployment and easy consumption.

### Setup & Usage

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/your-username/imagine.git
    cd imagine
    ```

2.  **Install dependencies:**
    ```bash
    pip install torch diffusers transformers accelerate flask Pillow argparse requests base64
    ```
    (For CUDA (NVIDIA GPU) usage, ensure `torch` is correctly installed, e.g.: `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118`)

3.  **Specify your Stable Diffusion model:**
    Edit `imagine.py` and set `DEFAULT_MODEL` to the path of your `.safetensors` or `.ckpt` model file (e.g., `dreamshaper_8.safetensors`).

4.  **Configure Server Options (Device, Precision):**
    Instead of modifying `imagine.py`, you can configure the compute device and floating-point precision directly via command-line arguments when running the server.
    *   `--device` or `-d`: Specify `'cpu'`, `'cuda'` (for NVIDIA GPUs), or `'mps'` (for Apple Silicon) for your model's computation. Defaults to `'cpu'`.
    *   `--fp_prec` or `-f`: Set the floating-point precision to `16` (for `torch.float16`) or `32` (for `torch.float32`). `float16` can offer faster inference and lower VRAM usage on compatible hardware (like NVIDIA GPUs), but might affect quality. Defaults to `32`.

5.  **Run the server:**
    ```bash
    python imagine.py --host '0.0.0.0' -p 5000 -d cuda -f 16 # Example for CUDA with float16
    # python imagine.py # Runs with defaults (cpu, float32)
    ```
    The server will start on `http://0.0.0.0:5000/`.

6.  **Send a POST request to `/generate`:**

    The `/generate` endpoint expects a JSON payload with your generation parameters. The response will be a JSON object containing the `img` (base64-encoded PNG) and the `seed`. If `stream` is enabled, it will return a stream of JSON objects.

    **Available parameters in the JSON payload:**
    *   `prompt` (string, **required**): The text prompt for image generation.
    *   `model` (string, optional): Path to the Stable Diffusion model file. Defaults to `DEFAULT_MODEL` set in `imagine.py`.
    *   `width` (int, optional): Output image width in pixels. Default: `512`.
    *   `height` (int, optional): Output image height in pixels. Default: `512`.
    *   `num_steps` (int, optional): Number of inference steps. Default: `25`.
    *   `guidance` (float, optional): Classifier-free guidance scale. Default: `7.0`.
    *   `sampler` (string, optional): Sampler algorithm. Available: `'ddim'`, `'euler'`, `'euler a'`, `'heun'`, `'lms'`, `'dpm++ 2m'`, `'dpm++ 2s'`, `'dpm++ sde'`, `'dpm2'`, `'dpm2 a'`. Default: `'dpm++ 2m'`.
    *   `seed` (int, optional): Random seed for reproducibility. Default: a random integer.
    *   `neg` (string, optional): Negative prompt. Default: `''` (empty string).
    *   `img` (string, optional): Base64-encoded input image (data URI format, e.g., `data:image/png;base64,...`). If provided, enables `img2img` mode. Default: `None`.
    *   `strength` (float, optional): Denoising strength for `img2img` mode (0.0 to 1.0). Controls how much the image is changed. Default: `0.8`.
    *   `stream` (int, optional): If set to an integer `N > 0`, intermediate images will be streamed every `N` steps as separate JSON objects. If `null` or `0`, only the final image is returned. Default: `None`.

    ---

    **Example: Basic Text-to-Image (txt2img)**
    ```bash
    curl -X POST -H "Content-Type: application/json" \
         -d '{
             "model": "/path/to/your/dreamshaper_8.safetensors",
             "prompt": "a photo of an astronaut riding a horse on mars, epic, cinematic, detailed",
             "width": 768,
             "height": 512,
             "num_steps": 25,
             "guidance": 7.0,
             "sampler": "dpm++ 2m",
             "seed": 12345,
             "neg": "ugly, deformed, blurry, low quality"
         }' \
         http://localhost:5000/generate | jq .
    ```
    The response will be a JSON object containing the `img` string and the `seed`.

    ---

    **Example: Image-to-Image (img2img)**
    (Replace `<base64_encoded_image>` with your actual base64 encoded image data).
    ```bash
    echo '{
        "prompt": "a futuristic city at sunset, detailed, neon lights",
        "img": "<base64_encoded_image>",
        "strength": 0.7,
        "width": 512,
        "height": 512,
        "sampler": "euler a",
        "num_steps": 30,
        "neg": "blurry, low quality"
    }' | curl -X POST -H "Content-Type: application/json" -d @- http://localhost:5000/generate | jq .
    ```

    ---

    **Example: Streaming Intermediate Steps**
    This will stream multiple JSON objects. Each object, except the last one, will contain an `img` (intermediate step). The final object will contain the `img` of the completed generation.
    ```bash
    curl -X POST -H "Content-Type: application/json" \
         -d '{
             "prompt": "a cat with a tiny hat, watercolor painting",
             "width": 512,
             "height": 512,
             "num_steps": 25,
             "stream": 5
         }' \
         http://localhost:5000/generate
    # This will output multiple JSON lines.
    # To process this, you might use tools like `jq -nc --stream 'fromjson'` or handle it in your code.
    ```

### Imagine CLI

### Description

A simple command-line script for generating images based on a text prompt using the `diffusers` library.

### Usage

```
usage: imagine [-m MODEL] [-o OUTPUT] [-w WIDTH] [-h HEIGHT] [-n NUM_STEPS] [-g GUIDANCE] [-s SAMPLER] [--seed SEED] [--neg NEG] [--stream STREAM] [--help] prompt [prompt ...]

SD image generator

positional arguments:
  prompt                Prompt for model

options:
  -m, --model MODEL     SD model
  -o, --output OUTPUT   Output image
  -w, --width WIDTH     Output image width
  -h, --height HEIGHT   Output image height
  -n, --num_steps NUM_STEPS
                        Number of steps
  -g, --guidance GUIDANCE
                        Guidance scale
  -s, --sampler SAMPLER
                        SD Sampler ['DDIM', 'Euler', 'Euler a', 'Heun', 'LMS', 'DPM++ 2M', 'DPM++ 2S', 'DPM++ SDE', 'DPM2', 'DPM2 a']
  --seed SEED           Seed
  --neg NEG             Negative prompt
  --stream STREAM       Stream steps samples to output image
  --help
```

#### Example Usage

```bash
./imagine-cli.py 'a photo of an astronaut riding a horse on mars, epic, cinematic, detailed' -w 768 -h 512 -n 25 -g 7.0 -s 'DPM++ 2M' --neg 'ugly, deformed, blurry, low quality'
```

### Output

The script will save the generated image to the current directory with a filename based on the prompt or a timestamp.

## Advanced Deployment: Running as a Systemd Service

For persistent and reliable operation, you can set up **Imagine** as a `systemd` service. This ensures the server starts automatically on boot and restarts in case of crashes.

**1. Create Symlinks and Ensure Executability:**

Ensure both your server script (`imagine.py`) and CLI utility script (`imagine-cli.py`) are executable and symlinked to a common `PATH` directory like `/usr/bin/`.

```bash
# Make the scripts executable
chmod +x /path/to/imagine/imagine.py
chmod +x /path/to/imagine/imagine-cli.py

# Create symlinks
# Replace `/path/to/imagine` with the actual path to your project directory if different
sudo ln -s /path/to/imagine/imagine.py /usr/bin/imagine-server
sudo ln -s /path/to/imagine/imagine-cli.py /usr/bin/imagine
```

**2. Create the Systemd Service File:**

Create a file named `imagine.service` in `/etc/systemd/system/`:

```bash
sudo nano /etc/systemd/system/imagine.service
```

Paste the following content into the file:

```ini
[Unit]
Description=Imagine: Stable Diffusion Image Generation Server
After=network.target syslog.target

[Service]
# REPLACE 'arch' WITH YOUR LINUX USERNAME!
# Run the service as your current user.
# This simplifies permissions as the script and model are likely in your home directory.
User=arch

# The command to execute when the service starts.
# Ensure /usr/bin/imagine-server points to your main server script (imagine.py).
ExecStart=/usr/bin/imagine-server

# Restart the service if it crashes
Restart=on-failure
RestartSec=5s

# Standard output and error will be directed to the systemd journal for easy debugging
StandardOutput=journal
StandardError=journal

# Type of service: simple (default) or forking
Type=simple

[Install]
# This unit should be started when the system reaches multi-user.target (normal boot)
WantedBy=multi-user.target
```

**Important Notes:**
*   **Replace `arch` with your actual Linux username!**
*   Ensure `/usr/bin/imagine` symlink correctly points to your **server script** (`imagine.py`).

**3. Enable and Start the Service:**

After saving the `imagine.service` file:

```bash
# Reload systemd to recognize the new service
sudo systemctl daemon-reload

# Enable the service to start on boot
sudo systemctl enable imagine.service

# Start the service immediately
sudo systemctl start imagine.service
```

**4. Check Service Status and Logs:**

To verify that the service is running correctly:

```bash
sudo systemctl status imagine.service
```

To view real-time logs for debugging:

```bash
journalctl -u imagine.service -f
```