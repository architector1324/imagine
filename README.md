## âœ¨ Imagine: A Lightweight Stable Diffusion Image Generation API

![](logo.png)

*Image generated by Imagine: "a photo of an astronaut riding a horse on mars, epic, cinematic, detailed"*

**Imagine** is a simple yet powerful HTTP server designed for generating images from text or other images using Stable Diffusion models and the Hugging Face `diffusers` library. It provides a single, straightforward endpoint that takes a JSON request and returns the generated image(s) as base64-encoded string(s), perfect for quick integration into your applications.

### Key Features

*   **Minimalist API:** One easy-to-use `/generate` endpoint for all your image generation needs.
*   **Versatile Generation:** Supports both **Text-to-Image (txt2img)** and **Image-to-Image (img2img)** capabilities.
*   **Live Progress Streaming:** Get real-time updates of the generation process by streaming intermediate steps directly to your client.
*   **Base64 Output:** Seamlessly receive generated images (both final and intermediate steps) as base64 strings, making them easy to embed directly into web pages, mobile apps, or other services without managing file storage.
*   **Comprehensive Parameters:** Control image generation parameters like `model` (optional, path to specific model file), `width`, `height`, `num_steps`, `guidance_scale`, `sampler`, `seed`, `negative_prompt`, **input image (`img`), diffusion strength (`strength`)** via the JSON payload. Server startup arguments (`--device`, `--full_prec`) control **floating-point precision** and compute device.
*   **Offline Mode Support:** Run image generation completely offline once models are downloaded, ideal for local and secure deployments.
*   **Built with Diffusers:** Leveraging robust and popular Python libraries for reliability and ease of use.
*   **Hardware Agnostic:** Supports CPU, CUDA (NVIDIA), MPS (Apple Silicon), and potentially ROCm (AMD) depending on your PyTorch setup.

### Why Imagine?

**Imagine** is inspired by the philosophy of tools like **Ollama** and offers a similar approach for Stable Diffusion models. It is ideal for developers needing a lightweight solution to run Stable Diffusion image generation **as a local background service**.

This enables integration from **anywhere**: command-line scripts, Python applications, web pages, or other services. With **offline mode support**, you can ensure privacy and consistent performance. You no longer need to worry about the overhead and complexity of more feature-rich diffusion UIs; Imagine provides fast, API-driven access to Stable Diffusion, designed for seamless deployment and easy consumption.

### Setup & Usage

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/your-username/imagine.git
    cd imagine
    ```

2.  **Install dependencies:**
    ```bash
    pip install torch diffusers transformers accelerate Pillow argparse requests base64
    ```
    (For CUDA (NVIDIA GPU) usage, ensure `torch` is correctly installed, e.g.: `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118`)

3.  **Specify your Stable Diffusion model:**
    Edit `imagine.py` and set `DEFAULT_MODEL` to the path of your `.safetensors` or `.ckpt` model file (e.g., `dreamshaper_8.safetensors`).

4.  **Configure Server Options (Device, Precision):**
    You can configure the compute device and floating-point precision directly via command-line arguments when running the server.
    *   `--device` or `-d`: Specify `'cpu'`, `'cuda'` (for NVIDIA GPUs), or `'mps'` (for Apple Silicon) for your model's computation. Defaults to `'cuda'`.
    *   `--full_prec` or `-f`: Use this flag to enable `torch.float32` (full precision). By default, `torch.float16` (half precision) is used, which can offer faster inference and lower VRAM usage on compatible hardware (like NVIDIA GPUs) but might affect quality.

5.  **Run the server:**
    ```bash
    python imagine.py --host '0.0.0.0' -p 5000 -d cuda --full_prec # Example for CUDA with float32
    # python imagine.py # Runs with defaults (cuda, float16)
    ```
    The server will start on `http://0.0.0.0:5000/`.

6.  **Send a POST request to `/generate`:**

    The `/generate` endpoint expects a JSON payload with your generation parameters. The response will be a JSON object containing the `img` (base64-encoded PNG) and the `seed`. If `stream` is enabled, it will return a stream of JSON objects.

    **Available parameters in the JSON payload:**
    *   `prompt` (string, **required**): The text prompt for image generation.
    *   `model` (string, optional): Path to the Stable Diffusion model file. Defaults to `DEFAULT_MODEL` set in `imagine.py`.
    *   `width` (int, optional): Output image width in pixels. Default: `512`.
    *   `height` (int, optional): Output image height in pixels. Default: `512`.
    *   `num_steps` (int, optional): Number of inference steps. Default: `25`.
    *   `guidance` (float, optional): Classifier-free guidance scale. Default: `7.0`.
    *   `sampler` (string, optional): Sampler algorithm. Available: `'ddim'`, `'euler'`, `'euler a'`, `'heun'`, `'lms'`, `'dpm++ 2m'`, `'dpm++ 2s'`, `'dpm++ sde'`, `'dpm2'`, `'dpm2 a'`. Default: `'dpm++ 2m'`.
    *   `seed` (int, optional): Random seed for reproducibility. Default: a random integer represented as string.
    *   `neg` (string, optional): Negative prompt. Default: `''` (empty string).
    *   `img` (string, optional): Base64-encoded input image (data URI format, e.g., `data:image/png;base64,...`). If provided, enables `img2img` mode. Default: `None`.
    *   `strength` (float, optional): Denoising strength for `img2img` mode (0.0 to 1.0). Controls how much the image is changed. Default: `0.8`.
    *   `stream` (int, optional): If set to an integer `N > 0`, intermediate images will be streamed every `N` steps as separate JSON objects. If `null` or `0`, only the final image is returned. Default: `None`.

    ---

    **Example: Basic Text-to-Image (txt2img)**
    ```bash
    curl -X POST -H "Content-Type: application/json" \
         -d '{
             "model": "/path/to/your/dreamshaper_8.safetensors",
             "prompt": "a photo of an astronaut riding a horse on mars, epic, cinematic, detailed",
             "width": 768,
             "height": 512,
             "num_steps": 25,
             "guidance": 7.0,
             "sampler": "dpm++ 2m",
             "seed": 591445185899376350,
             "neg": "ugly, deformed, blurry, low quality"
         }' \
         http://localhost:5000/generate | jq .
    ```
    The response will be a JSON object containing the `img` string and the `seed`.

    ---

    **Example: Image-to-Image (img2img)**
    (Replace `<base64_encoded_image>` with your actual base64 encoded image data).
    ```bash
    echo '{
        "prompt": "a futuristic city at sunset, detailed, neon lights",
        "img": "<base64_encoded_image>",
        "strength": 0.7,
        "width": 512,
        "height": 512,
        "sampler": "euler a",
        "num_steps": 30,
        "neg": "blurry, low quality"
    }' | curl -X POST -H "Content-Type: application/json" -d @- http://localhost:5000/generate | jq .
    ```

    ---

    **Example: Streaming Intermediate Steps**
    This will stream multiple JSON objects. Each object, except the last one, will contain an `img` (intermediate step). The final object will contain the `img` of the completed generation.
    ```bash
    curl -X POST -H "Content-Type: application/json" \
         -d '{
             "prompt": "a cat with a tiny hat, watercolor painting",
             "width": 512,
             "height": 512,
             "num_steps": 25,
             "stream": 5
         }' \
         http://localhost:5000/generate
    # This will output multiple JSON lines.
    # To process this, you might use tools like `jq -nc --stream 'fromjson'` or handle it in your code.
    ```

## Imagine CLI

**Note:** This `imagine-cli.py` script is a separate utility for image generation, which can interact with the `imagine.py` server.

### Description

A simple yet powerful command-line script for generating images based on a text prompt using the `diffusers` library. It provides an extended output format for full reproducibility and seamless integration with the Imagine Web UI.

### Usage

```
usage: imagine [-m MODEL] [-o OUTPUT] [-w WIDTH] [-h HEIGHT] [-n NUM_STEPS] [-g GUIDANCE] [-d STRENGTH] [--sampler SAMPLER] [-i IMG] [-f HIRES] [--seed SEED] [--neg NEG] [-s STREAM] [-a ADDRESS] [--help] prompt [prompt ...]

SD image generator

positional arguments:
  prompt                Prompt for model

options:
  -m, --model MODEL     SD model
  -o, --output OUTPUT   Filename to save the image and accompanying JSON (default is timestamp-based, e.g., `20231027_153045.png` and `20231027_153045.json`).
  -w, --width WIDTH     Output image width
  -h, --height HEIGHT   Output image height
  -n, --num_steps NUM_STEPS
                        Number of steps
  -g, --guidance GUIDANCE
                        Guidance scale
  -d, --strength STRENGTH
                        Denoising strength (only if `--img` provided)
  --sampler SAMPLER     SD Sampler ['ddim', 'euler', 'euler a', 'heun', 'lms', 'dpm++ 2m', 'dpm++ 2s', 'dpm++ sde', 'dpm2', 'dpm2 a']
  -i, --img IMG         Input image
  -f, --hires HIRES     High Resolution fix
  --seed SEED           Seed
  --neg NEG             Negative prompt
  -s, --stream STREAM   Stream steps samples to output image
  -a, --address ADDRESS
                        Server host address
  --help
```

#### Example Usage

```bash
./imagine-cli.py 'a photo of an astronaut riding a horse on mars, epic, cinematic, detailed' -w 768 -h 512 -n 25 -g 7.0 --sampler 'dpm++ 2m' --neg 'ugly, deformed, blurry, low quality'
```

### Output Format and Reproducibility

The `imagine-cli.py` script defaults to generating a JSON file alongside the generated image. This JSON file contains all the parameters used for the generation (`meta` field) and the generated image itself in base64 format (`out` field).

This standardized output ensures full reproducibility and seamless integration.

**JSON Output Structure:**

```json
{
    "meta": {
        "model": "/home/arch/AI/models/sd/dreamshaper_8.safetensors",
        "prompt": "a photo of an astronaut riding a horse on mars, epic, cinematic, detailed",
        "width": 768,
        "height": 512,
        "num_steps": 25,
        "guidance": 7.0,
        "sampler": "dpm++ 2m",
        "seed": "591445185899376350",
        "neg": "ugly, deformed, blurry, low quality",
        "stream": 1,
        "img": null,
        "strength": 0.8
    },
    "out": "<base64 encoded image string>"
}
```

*   `meta`: Contains all the parameters (prompt, model, dimensions, steps, etc.) that were sent to the Imagine server for this specific generation. This provides full traceability of how the image was created.
*   `out`: The base64 string of the generated image.

**Reproducibility with the Web UI:**

**Key Point:** This generated JSON file (e.g., `20231027_153045.json` if saved by timestamp) can be directly loaded into the [Imagine Web UI](#imagine-web-ui) using the "Load Settings from JSON" button. This allows you to instantly restore all parameters used for a specific generation and view the result, making the process of reproducing, adjusting, and sharing your creations incredibly simple.

### Output Files

By default, the script will save two files to the current directory:
*   A `.png` image file with a name based on the prompt or a timestamp (e.g., `my_prompt_12345.png` or `20231027_153045.png`).
*   A `.json` file with the same base name, containing the full generation metadata and the base64 image (e.g., `my_prompt_12345.json` or `20231027_153045.json`).

You can control the output image filename using the `-o` or `--output` flag. If a filename is specified, both the `.png` and `.json` will use that base name.

## Imagine Web UI

![](./ui/demo.png)

In addition to the command-line interface, **Imagine** also comes with a simple yet powerful web UI located in `ui/imagine-ui.html`. This UI provides a convenient way to interact with the running Imagine server, allowing you to easily configure all generation parameters and visualize results directly in your browser without using `curl` or writing custom scripts.

It is ideal for quick experimentation, testing parameters, or demonstrating the server's capabilities.

### Key UI Features

*   **Intuitive Interface:** All server parameters (`prompt`, `negative prompt`, `width`, `height`, `num_steps`, `guidance scale`, `sampler`, `seed`, `strength`, `stream`) are exposed through user-friendly input fields.
*   **Image-to-Image Support:** Easily upload an input image for `img2img` operations with live preview.
*   **Real-time Progress Visualization:** When `stream` is enabled, observe the image generation progress in real-time as intermediate steps are displayed.
*   **Manage Settings:** Load and save your entire generation configuration (including prompts, parameters, and even the last generated image) to/from JSON files, making it easy to share or reuse specific settings. **This includes the ability to load JSON files generated by the `imagine-cli.py` utility for full reproducibility of previous generations and automatic population of all applied parameters.**
*   **Real-time Feedback:** Get instant messages about generation status, errors, and cancellations.

### Usage

**Prerequisite:** Ensure your `imagine.py` server is running (see [Run the server](#run-the-server) section).

1.  **Open in Browser:** Navigate to the `ui/` directory and open the `imagine-ui.html` file in your favorite web browser.
    ```
    file:///path/to/your/imagine/ui/imagine-ui.html
    ```
    (Replace `/path/to/your/imagine` with the actual location of your cloned repository).

2.  **Configure Server Address:** In the "Server & Model" section, verify or set the "Imagine Server Address" (defaults to `http://localhost:5000`).

3.  **Configure Parameters & Generate:** Fill in your desired prompts and adjust other parameters. Click the "Generate" button. *Alternatively, to load previously generated settings, use the "Load Settings from JSON" button in the "Configuration" section and select a JSON file created by the `imagine-cli.py` utility.*

4.  **View Results:** The generated image (or intermediate steps if streaming is enabled) will appear in the main content area. The final seed will also be displayed.

> **Note on CORS:** If you encounter connectivity issues (e.g., "Failed to fetch" errors), this might be due to Cross-Origin Resource Sharing (CORS) policies. Ensure your browser allows local file access to external resources, or consider running a simple local web server to serve the `ui/` directory (e.g., `python3 -m http.server 8000` from your `imagine` project root, then navigate to `http://localhost:8000/ui/imagine-ui.html`).


## Advanced Deployment: Running as a Systemd Service

For persistent and reliable operation, you can set up **Imagine** as a `systemd` service. This ensures the server starts automatically on boot and restarts in case of crashes.

**1. Create Symlinks and Ensure Executability:**

Ensure both your server script (`imagine.py`) and CLI utility script (`imagine-cli.py`) are executable and symlinked to a common `PATH` directory like `/usr/bin/`.

```bash
# Make the scripts executable
chmod +x /path/to/imagine/imagine.py
chmod +x /path/to/imagine/imagine-cli.py

# Create symlinks
# Replace `/path/to/imagine` with the actual path to your project directory if different
sudo ln -s /path/to/imagine/imagine.py /usr/bin/imagine-server
sudo ln -s /path/to/imagine/imagine-cli.py /usr/bin/imagine
```

**2. Create the Systemd Service File:**

Create a file named `imagine.service` in `/etc/systemd/system/`:

```bash
sudo nano /etc/systemd/system/imagine.service
```

Paste the following content into the file:

```ini
[Unit]
Description=Imagine: Stable Diffusion Image Generation Server
After=network.target syslog.target

[Service]
# REPLACE 'arch' WITH YOUR LINUX USERNAME!
# Run the service as your current user.
# This simplifies permissions as the script and model are likely in your home directory.
User=arch

# The command to execute when the service starts.
# Ensure /usr/bin/imagine-server points to your main server script (imagine.py).
# It's recommended to include server arguments like device and precision here.
ExecStart=/usr/bin/imagine-server -d cuda --full_prec

# Restart the service if it crashes
Restart=on-failure
RestartSec=5s

# Standard output and error will be directed to the systemd journal for easy debugging
StandardOutput=journal
StandardError=journal

# Type of service: simple (default) or forking
Type=simple

[Install]
# This unit should be started when the system reaches multi-user.target (normal boot)
WantedBy=multi-user.target
```

**Important Notes:**
*   **Replace `arch` with your actual Linux username!**
*   Ensure `/usr/bin/imagine-server` symlink correctly points to your **server script** (`imagine.py`).
*   The `ExecStart` line in `imagine.service` should specify desired server arguments (e.g., `-d cuda --full_prec`).

**3. Enable and Start the Service:**

After saving the `imagine.service` file:

```bash
# Reload systemd to recognize the new service
sudo systemctl daemon-reload

# Enable the service to start on boot
sudo systemctl enable imagine.service

# Start the service immediately
sudo systemctl start imagine.service
```

**4. Check Service Status and Logs:**

To verify that the service is running correctly:

```bash
sudo systemctl status imagine.service
```

To view real-time logs for debugging:

```bash
journalctl -u imagine.service -f
```